#!/usr/bin/env python3
"""
DcisionAI Model Builder Tool - Bedrock Agent Pattern
===================================================

High-quality optimization model generation using Bedrock Agent() pattern.
Outputs structured models ready for the solver tool to consume.

Uses true parallel execution with asyncio.gather() for performance.
Compatible with Bedrock auto-assignment for throttling avoidance.

Copyright (c) 2025 DcisionAI. All rights reserved.
"""

import logging
import json
import asyncio
import uuid
import re
from typing import Dict, Any, List, Optional, Union, Tuple
from datetime import datetime
from dataclasses import dataclass, field
from enum import Enum

# Strands framework imports
try:
    from strands import Agent
    STRANDS_AVAILABLE = True
except ImportError:
    STRANDS_AVAILABLE = False
    logging.error("Strands framework not available - install with: pip install strands")
    raise ImportError("Strands framework is required for model building")

try:
    from src.shared.throttling import get_platform_throttle_manager
except ImportError:
    logging.warning("Throttling manager not available - using default")
    def get_platform_throttle_manager():
        return None

logger = logging.getLogger(__name__)

# ==================== CORE DATA STRUCTURES ====================

class ModelType(Enum):
    """Optimization model types for solver compatibility"""
    LINEAR_PROGRAMMING = "linear_programming"
    INTEGER_PROGRAMMING = "integer_programming"
    MIXED_INTEGER_PROGRAMMING = "mixed_integer_programming"
    QUADRATIC_PROGRAMMING = "quadratic_programming"
    NONLINEAR_PROGRAMMING = "nonlinear_programming"
    CONSTRAINT_PROGRAMMING = "constraint_programming"

class SolverType(Enum):
    """Supported solver types"""
    GUROBI = "gurobi"
    CPLEX = "cplex"
    OR_TOOLS = "or_tools"
    PULP = "pulp"
    CVXPY = "cvxpy"
    PYOMO = "pyomo"

@dataclass
class DecisionVariable:
    """Decision variable specification for solver"""
    name: str
    variable_type: str  # "continuous", "integer", "binary"
    domain: str  # "real", "integer", "binary"
    bounds: Tuple[Optional[float], Optional[float]]
    description: str
    indices: Optional[List[str]] = None
    dimensions: Optional[Dict[str, List[str]]] = None

@dataclass
class OptimizationConstraint:
    """Constraint specification for solver"""
    name: str
    constraint_type: str  # "equality", "inequality", "bound"
    expression: str  # Mathematical expression
    sense: str  # "<=", ">=", "=="
    rhs_value: Union[float, str]
    description: str
    priority: str = "normal"  # "critical", "important", "normal"
    constraint_data: Optional[Dict[str, Any]] = None

@dataclass
class ObjectiveFunction:
    """Objective function specification for solver"""
    name: str
    sense: str  # "minimize", "maximize"
    expression: str
    description: str
    weight: float = 1.0
    priority: int = 1

@dataclass
class ModelDataSchema:
    """Data schema specification for solver"""
    parameters: Dict[str, Dict[str, Any]]  # parameter_name -> {type, description, sample_data}
    sets: Dict[str, List[str]]  # set_name -> sample_values
    scalars: Dict[str, float]  # scalar_name -> sample_value

@dataclass
class OptimizationModel:
    """Complete optimization model for solver consumption"""
    model_id: str
    model_name: str
    model_type: ModelType
    intent_classification: str
    
    # Core model components for solver
    decision_variables: List[DecisionVariable]
    constraints: List[OptimizationConstraint]
    objective_functions: List[ObjectiveFunction]
    data_schema: ModelDataSchema
    
    # Solver compatibility
    compatible_solvers: List[SolverType]
    recommended_solver: SolverType
    
    # Model metadata
    model_complexity: str
    estimated_solve_time: str
    model_validation_score: float
    generation_metadata: Dict[str, Any] = field(default_factory=dict)

# ==================== ASYNC AGENT WRAPPERS ====================

class AsyncModelingAgent:
    """Async wrapper for modeling agents using Bedrock Agent() pattern"""
    
    def __init__(self, name: str, system_prompt: str):
        self.name = name
        if not STRANDS_AVAILABLE:
            raise ImportError("Strands framework required for agent initialization")
        self.agent = Agent(name=name, system_prompt=system_prompt)
    
    async def analyze_async(self, prompt: str) -> Dict[str, Any]:
        """Execute agent analysis asynchronously"""
        try:
            # Use asyncio.to_thread for true async execution
            response = await asyncio.to_thread(self.agent, prompt)
            
            # Extract response content
            response_text = response.content if hasattr(response, 'content') else str(response)
            
            # Parse JSON response
            try:
                result = json.loads(response_text)
                result["agent_name"] = self.name
                result["status"] = "success"
                return result
            except json.JSONDecodeError:
                # Try to extract JSON from text
                cleaned = self._clean_response(response_text)
                try:
                    result = json.loads(cleaned)
                    result["agent_name"] = self.name
                    result["status"] = "success"
                    return result
                except:
                    return {
                        "agent_name": self.name,
                        "status": "parse_error",
                        "error": "Failed to parse agent response",
                        "raw_response": response_text[:500]  # First 500 chars for debugging
                    }
                    
        except Exception as e:
            logger.error(f"Agent {self.name} execution failed: {e}")
            return {
                "agent_name": self.name,
                "status": "error",
                "error": str(e)
            }
    
    def _clean_response(self, text: str) -> str:
        """Clean response text to extract JSON"""
        # Remove markdown code blocks
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)
        
        # Extract JSON pattern
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        match = re.search(json_pattern, text, re.DOTALL)
        
        return match.group(0) if match else text.strip()

# ==================== MODEL BUILDING SPECIALISTS ====================

class ModelBuilderTool:
    """
    High-quality optimization model generation using true parallel execution.
    Uses Bedrock Agent() pattern for auto-assignment and throttling avoidance.
    """
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.ModelBuilderTool")
        self.throttle_manager = get_platform_throttle_manager()
        
        # Initialize all specialist agents for parallel execution
        self.agents = self._initialize_modeling_agents()
        
        self.logger.info("âœ… Model Builder Tool initialized with 6 parallel modeling agents")
    
    def _initialize_modeling_agents(self) -> Dict[str, AsyncModelingAgent]:
        """Initialize all modeling specialist agents"""
        
        agents = {}
        
        # Mathematical Formulation Specialist
        agents["mathematical_formulation"] = AsyncModelingAgent(
            name="mathematical_formulation_specialist",
            system_prompt="""You are a Mathematical Formulation specialist for optimization model building.

EXPERTISE: Determine optimal mathematical formulation type and structure
FOCUS: Model type selection, problem structure analysis, mathematical correctness

ANALYSIS TASKS:
- Determine optimal model type (LP, IP, MIP, QP, NLP, CP)
- Identify decision variable types and structure
- Assess problem complexity and solver requirements
- Recommend mathematical formulation approach

RESPONSE FORMAT (JSON only):
{
    "model_type": "LINEAR_PROGRAMMING|MIXED_INTEGER_PROGRAMMING|QUADRATIC_PROGRAMMING|NONLINEAR_PROGRAMMING|CONSTRAINT_PROGRAMMING",
    "formulation_rationale": "Clear explanation of why this model type is optimal",
    "problem_structure": {
        "variable_types": ["continuous", "integer", "binary"],
        "constraint_types": ["linear", "quadratic", "logical"],
        "objective_type": "linear",
        "problem_size": "small|medium|large"
    },
    "recommended_solvers": ["gurobi", "cplex", "or_tools"],
    "complexity_assessment": {
        "computational_complexity": "low|medium|high",
        "solver_requirements": "standard|specialized|advanced"
    }
}

Provide mathematically rigorous analysis for solver-ready models."""
        )
        
        # Variable Design Specialist
        agents["variable_design"] = AsyncModelingAgent(
            name="variable_design_specialist",
            system_prompt="""You are a Variable Design specialist for optimization model building.

EXPERTISE: Design optimal decision variable architecture for solver compatibility
FOCUS: Variable structure, indexing, bounds, and solver integration

DESIGN TASKS:
- Create comprehensive variable specifications
- Design efficient indexing schemes
- Determine optimal variable bounds
- Ensure solver compatibility

RESPONSE FORMAT (JSON only):
{
    "decision_variables": [
        {
            "name": "x",
            "full_name": "x[i,j]",
            "variable_type": "continuous|integer|binary",
            "domain": "real|integer|binary",
            "bounds": {"lower": 0.0, "upper": null},
            "description": "Production quantity of product i on line j",
            "indices": ["products", "production_lines"],
            "dimensions": {
                "products": ["P1", "P2", "P3"],
                "production_lines": ["L1", "L2", "L3", "L4"]
            },
            "solver_notation": {
                "gurobi": "x = model.addVars(products, lines, name='x')",
                "or_tools": "x = {(i,j): solver.NumVar(0, infinity, f'x_{i}_{j}') for i,j in product(products, lines)}",
                "pulp": "x = pl.LpVariable.dicts('x', [(i,j) for i in products for j in lines], lowBound=0)"
            }
        }
    ],
    "variable_summary": {
        "total_variables": 50,
        "variable_breakdown": {"continuous": 45, "integer": 3, "binary": 2},
        "indexing_complexity": "medium",
        "solver_efficiency": "high"
    }
}

Design variables for optimal solver performance and mathematical clarity."""
        )
        
        # Constraint Modeling Specialist  
        agents["constraint_modeling"] = AsyncModelingAgent(
            name="constraint_modeling_specialist",
            system_prompt="""You are a Constraint Modeling specialist for optimization model building.

EXPERTISE: Design comprehensive constraint systems for solver execution
FOCUS: Mathematical correctness, solver compatibility, constraint efficiency

MODELING TASKS:
- Create mathematically sound constraint formulations
- Design solver-compatible constraint expressions
- Ensure constraint completeness and consistency
- Optimize constraint efficiency

RESPONSE FORMAT (JSON only):
{
    "constraints": [
        {
            "name": "production_capacity_limit",
            "constraint_type": "inequality",
            "expression": "sum(x[i,j] * processing_time[i] for i in products) <= line_capacity[j]",
            "sense": "<=",
            "rhs_value": "line_capacity[j]",
            "description": "Production capacity limit for each line j",
            "priority": "critical",
            "constraint_data": {
                "parameters": ["processing_time", "line_capacity"],
                "variables": ["x"],
                "index_sets": ["products", "production_lines"]
            },
            "solver_implementations": {
                "gurobi": "model.addConstrs((gp.quicksum(x[i,j] * processing_time[i] for i in products) <= line_capacity[j] for j in lines), name='capacity')",
                "or_tools": "for j in lines: solver.Add(sum(x[i,j] * processing_time[i] for i in products) <= line_capacity[j])",
                "pulp": "for j in lines: prob += pl.lpSum([x[i,j] * processing_time[i] for i in products]) <= line_capacity[j]"
            }
        }
    ],
    "constraint_summary": {
        "total_constraints": 25,
        "constraint_types": {"equality": 8, "inequality": 15, "bounds": 2},
        "mathematical_correctness": 0.95,
        "solver_efficiency": "high"
    }
}

Create solver-ready constraints with mathematical rigor."""
        )
        
        # Objective Function Specialist
        agents["objective_design"] = AsyncModelingAgent(
            name="objective_design_specialist", 
            system_prompt="""You are an Objective Function specialist for optimization model building.

EXPERTISE: Design optimal objective functions for solver execution
FOCUS: Mathematical optimization goals, multi-objective handling, solver compatibility

DESIGN TASKS:
- Create mathematically optimal objective formulations
- Handle multi-objective optimization scenarios
- Ensure solver compatibility and efficiency
- Design objective function scaling and weighting

RESPONSE FORMAT (JSON only):
{
    "objective_functions": [
        {
            "name": "minimize_makespan",
            "sense": "minimize",
            "expression": "max_completion_time",
            "mathematical_form": "minimize z where z >= completion_time[i] for all i",
            "description": "Minimize maximum completion time across all products",
            "weight": 1.0,
            "priority": 1,
            "objective_data": {
                "variables": ["completion_time", "z"],
                "parameters": ["processing_time", "setup_time"],
                "auxiliary_constraints": ["z >= completion_time[i] for i in products"]
            },
            "solver_implementations": {
                "gurobi": "z = model.addVar(name='makespan'); model.addConstrs(z >= completion_time[i] for i in products); model.setObjective(z, GRB.MINIMIZE)",
                "or_tools": "z = solver.NumVar(0, solver.infinity(), 'makespan'); [solver.Add(z >= completion_time[i]) for i in products]; solver.Minimize(z)",
                "pulp": "z = pl.LpVariable('makespan', lowBound=0); [prob += z >= completion_time[i] for i in products]; prob += z"
            }
        }
    ],
    "objective_summary": {
        "objective_count": 1,
        "objective_type": "single|multi_objective|hierarchical",
        "optimization_complexity": "linear|quadratic|nonlinear",
        "solver_efficiency": "high"
    }
}

Design mathematically sound objectives for optimal solver performance."""
        )
        
        # RL Optimization Specialist
        agents["rl_optimization"] = AsyncModelingAgent(
            name="rl_optimization_specialist",
            system_prompt="""You are a Reinforcement Learning Optimization specialist for model enhancement.

EXPERTISE: RL-based model optimization, parameter tuning, adaptive optimization
FOCUS: Learning from historical performance, model parameter optimization, adaptive constraints

RL ENHANCEMENT TASKS:
- Optimize model parameters based on historical solve performance
- Learn better constraint formulations from solution patterns  
- Adapt objective weights based on business outcomes
- Implement dynamic parameter adjustment strategies

RESPONSE FORMAT (JSON only):
{
    "rl_enhancements": {
        "parameter_optimizations": [
            {
                "parameter": "constraint_tightness_factor",
                "original_value": 1.0,
                "rl_optimized_value": 0.92,
                "optimization_basis": "Q-learning on solve time vs feasibility trade-off",
                "performance_improvement": 0.18,
                "confidence": 0.85,
                "learning_episodes": 150
            }
        ],
        "adaptive_constraints": [
            {
                "constraint_name": "capacity_utilization",
                "adaptive_mechanism": "dynamic_tightening",
                "trigger_conditions": ["high_demand_periods", "resource_scarcity"],
                "adjustment_policy": "epsilon_greedy_exploration",
                "learned_parameters": {"exploration_rate": 0.1, "learning_rate": 0.01}
            }
        ],
        "objective_weight_learning": {
            "multi_objective_weights": {"cost": 0.65, "time": 0.25, "quality": 0.10},
            "learning_algorithm": "policy_gradient",
            "reward_function": "business_kpi_alignment",
            "convergence_status": "converged",
            "episodes_to_convergence": 200
        }
    },
    "rl_model_improvements": {
        "expected_solve_time_reduction": 0.22,
        "solution_quality_improvement": 0.15,
        "constraint_violation_reduction": 0.30,
        "business_objective_alignment": 0.88
    },
    "rl_implementation": {
        "algorithm": "Deep_Q_Network",
        "state_space": "model_parameters_and_historical_performance",
        "action_space": "parameter_adjustments_and_constraint_modifications",
        "reward_signal": "weighted_combination_of_solve_time_solution_quality_business_kpis"
    }
}

Apply RL techniques to continuously improve model performance."""
        )
        
        # Research Integration Specialist
        agents["research_integration"] = AsyncModelingAgent(
            name="research_integration_specialist",
            system_prompt="""You are a Research Integration specialist for cutting-edge optimization modeling.

EXPERTISE: Latest research integration, algorithmic improvements, advanced techniques
FOCUS: State-of-the-art methods, research literature insights, advanced formulations

RESEARCH INTEGRATION TASKS:
- Integrate latest optimization research and techniques
- Apply advanced mathematical programming methods
- Implement cutting-edge algorithmic improvements
- Incorporate recent academic and industry breakthroughs

RESPONSE FORMAT (JSON only):
{
    "research_enhancements": {
        "algorithmic_improvements": [
            {
                "technique": "lifted_cut_generation",
                "research_source": "Computational Optimization 2024",
                "description": "Advanced cutting plane generation for tighter LP relaxations",
                "implementation": "Add cutting planes during branch-and-bound for 15-30% solve time reduction",
                "expected_benefit": 0.25,
                "implementation_complexity": "medium",
                "solver_support": ["gurobi", "cplex"]
            }
        ],
        "formulation_improvements": [
            {
                "improvement": "symmetry_breaking_constraints",
                "mathematical_basis": "Group theory for equivalent solution elimination",
                "formulation": "Add lexicographic ordering constraints for symmetric variables",
                "performance_impact": "40% solution space reduction",
                "research_citation": "Mathematical Programming B, 2024"
            }
        ],
        "advanced_techniques": [
            {
                "technique": "benders_decomposition_enhancement",
                "application": "large_scale_production_scheduling",
                "description": "Enhanced Benders decomposition with machine learning acceleration",
                "implementation_details": "ML-guided cut selection and subproblem ordering",
                "scalability_improvement": "10x for problems >100,000 variables"
            }
        ]
    },
    "research_implementation_roadmap": {
        "immediate": ["constraint_preprocessing", "variable_bounds_tightening"],
        "short_term": ["cutting_plane_integration", "symmetry_breaking"],
        "advanced": ["benders_decomposition", "column_generation"],
        "experimental": ["quantum_annealing_hybrid", "neuromorphic_optimization"]
    },
    "literature_insights": {
        "recent_breakthroughs": ["learned_heuristics", "ml_guided_branching", "deep_learning_bounds"],
        "industry_applications": ["google_or_tools_improvements", "ibm_cplex_ml_integration"],
        "academic_developments": ["quantum_optimization_advances", "distributed_optimization"]
    }
}

Integrate cutting-edge research for state-of-the-art optimization models."""
        )
        
        # ML Predictive Analytics Specialist
        agents["ml_predictive"] = AsyncModelingAgent(
            name="ml_predictive_specialist",
            system_prompt="""You are a Machine Learning Predictive Analytics specialist for optimization enhancement.

EXPERTISE: ML-driven predictions, uncertainty modeling, predictive optimization
FOCUS: Demand forecasting, parameter prediction, uncertainty quantification, predictive constraints

ML PREDICTIVE TASKS:
- Generate ML-based demand and parameter forecasts
- Implement uncertainty modeling and robust optimization
- Create predictive constraints and adaptive parameters
- Design ML-enhanced optimization formulations

RESPONSE FORMAT (JSON only):
{
    "ml_predictions": {
        "demand_forecasting": {
            "forecast_model": "lstm_with_attention",
            "prediction_horizon": "4_weeks",
            "accuracy_metrics": {"mape": 0.08, "rmse": 12.5, "mae": 9.2},
            "predicted_demands": {
                "week_1": {"P1": 120, "P2": 145, "P3": 88},
                "week_2": {"P1": 125, "P2": 150, "P3": 92},
                "week_3": {"P1": 118, "P2": 142, "P3": 85},
                "week_4": {"P1": 130, "P2": 155, "P3": 95}
            },
            "confidence_intervals": {
                "week_1": {"P1": [110, 130], "P2": [135, 155], "P3": [80, 96]}
            }
        },
        "parameter_predictions": [
            {
                "parameter": "processing_time_variability",
                "ml_model": "gaussian_process_regression",
                "predicted_distribution": {"mean": 2.3, "std": 0.4, "distribution": "normal"},
                "prediction_confidence": 0.92,
                "factors_considered": ["machine_age", "operator_skill", "material_quality"]
            }
        ],
        "uncertainty_modeling": {
            "uncertain_parameters": ["demand", "processing_times", "resource_availability"],
            "uncertainty_representation": "scenario_trees",
            "scenario_generation": "monte_carlo_with_ml_guidance",
            "scenario_count": 100,
            "scenario_probabilities": "data_driven_clustering"
        }
    },
    "ml_enhanced_formulations": {
        "predictive_constraints": [
            {
                "constraint_name": "adaptive_capacity_constraint",
                "ml_component": "real_time_capacity_prediction",
                "formulation": "capacity[j,t] = base_capacity[j] * ml_efficiency_predictor(machine_state[j,t])",
                "update_frequency": "hourly",
                "prediction_model": "gradient_boosting_regressor"
            }
        ],
        "robust_optimization": {
            "approach": "distributionally_robust_optimization",
            "uncertainty_sets": "ml_learned_ambiguity_sets",
            "robustness_parameter": 0.05,
            "worst_case_guarantee": "95th_percentile_performance"
        },
        "adaptive_parameters": {
            "dynamic_pricing": "rl_based_price_optimization",
            "inventory_levels": "lstm_demand_responsive_safety_stock",
            "resource_allocation": "contextual_bandit_allocation"
        }
    },
    "ml_model_integration": {
        "feature_engineering": ["temporal_features", "cross_product_interactions", "lag_variables"],
        "model_selection": "automated_ml_with_hyperparameter_optimization",
        "validation_strategy": "time_series_cross_validation",
        "deployment_pipeline": "real_time_prediction_api",
        "monitoring": "drift_detection_and_model_retraining"
    }
}

Integrate ML predictions and uncertainty modeling for enhanced optimization."""
        )
        
        return agents
    
    async def build_optimization_model_parallel(
        self,
        intent_result: Dict[str, Any],
        data_result: Dict[str, Any],
        customer_id: str = "default",
        enable_rl: bool = True,
        enable_research: bool = True,
        enable_ml: bool = True
    ) -> OptimizationModel:
        """
        Build high-quality optimization model using TRUE parallel execution.
        Includes RL, Research, and ML enhancements.
        """
        start_time = datetime.now()
        model_id = f"model_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        
        try:
            self.logger.info(f"ðŸš€ Starting parallel model building with RL/Research/ML - {model_id}")
            
            # Prepare analysis context for all agents
            analysis_context = {
                "intent_result": intent_result,
                "data_result": data_result,
                "customer_id": customer_id,
                "model_id": model_id,
                "enable_enhancements": {
                    "rl_optimization": enable_rl,
                    "research_integration": enable_research,
                    "ml_predictive": enable_ml
                }
            }
            
            # Create analysis tasks for parallel execution
            agent_tasks = []
            
            # Core modeling agents (always execute)
            core_agents = ["mathematical_formulation", "variable_design", "constraint_modeling", "objective_design"]
            for agent_name in core_agents:
                agent = self.agents[agent_name]
                prompt = self._create_agent_prompt(agent_name, analysis_context)
                agent_tasks.append(agent.analyze_async(prompt))
            
            # Enhancement agents (conditionally execute)
            if enable_rl:
                agent = self.agents["rl_optimization"]
                prompt = self._create_rl_prompt(analysis_context)
                agent_tasks.append(agent.analyze_async(prompt))
            
            if enable_research:
                agent = self.agents["research_integration"]
                prompt = self._create_research_prompt(analysis_context)
                agent_tasks.append(agent.analyze_async(prompt))
            
            if enable_ml:
                agent = self.agents["ml_predictive"]
                prompt = self._create_ml_prompt(analysis_context)
                agent_tasks.append(agent.analyze_async(prompt))
            
            # Execute ALL agents in parallel using asyncio.gather
            self.logger.info(f"âš¡ Executing {len(agent_tasks)} agents in parallel")
            agent_results = await asyncio.gather(*agent_tasks, return_exceptions=True)
            
            # Process results and handle exceptions
            processed_results = {}
            successful_agents = 0
            
            expected_agents = core_agents + (["rl_optimization"] if enable_rl else []) + \
                             (["research_integration"] if enable_research else []) + \
                             (["ml_predictive"] if enable_ml else [])
            
            for i, (agent_name, result) in enumerate(zip(expected_agents, agent_results)):
                if isinstance(result, Exception):
                    self.logger.warning(f"Agent {agent_name} failed: {result}")
                    processed_results[agent_name] = {"status": "error", "error": str(result)}
                else:
                    processed_results[agent_name] = result
                    if result.get("status") == "success":
                        successful_agents += 1
            
            self.logger.info(f"âœ… Parallel execution completed: {successful_agents}/{len(expected_agents)} agents successful")
            
            # Build complete optimization model from parallel results
            optimization_model = self._assemble_optimization_model(
                model_id, intent_result, data_result, processed_results
            )
            
            # Calculate execution time
            execution_time = (datetime.now() - start_time).total_seconds()
            optimization_model.generation_metadata.update({
                "execution_time": execution_time,
                "parallel_execution": True,
                "successful_agents": successful_agents,
                "total_agents": len(expected_agents),
                "enhancements_applied": {
                    "rl_optimization": enable_rl and "rl_optimization" in processed_results,
                    "research_integration": enable_research and "research_integration" in processed_results,
                    "ml_predictive": enable_ml and "ml_predictive" in processed_results
                },
                "agent_results": processed_results
            })
            
            self.logger.info(f"âœ… Model building completed in {execution_time:.1f}s")
            return optimization_model
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            self.logger.error(f"âŒ Parallel model building failed: {e}")
            
            # Return minimal valid model on failure
            return self._create_fallback_model(model_id, intent_result, str(e), execution_time)
    
    def _create_agent_prompt(self, agent_name: str, context: Dict[str, Any]) -> str:
        """Create agent-specific prompts"""
        
        base_info = f"""
        Intent Analysis: {json.dumps(context['intent_result'])}
        Data Analysis: {json.dumps(context['data_result'])}
        Model ID: {context['model_id']}
        Customer ID: {context['customer_id']}
        """
        
        if agent_name == "mathematical_formulation":
            return f"""
            Analyze this optimization problem for mathematical formulation:
            {base_info}
            
            Determine the optimal model type and mathematical structure for solver execution.
            Focus on solver compatibility and computational efficiency.
            """
        
        elif agent_name == "variable_design":
            return f"""
            Design optimal decision variables for this optimization problem:
            {base_info}
            
            Create comprehensive variable specifications with solver-ready implementations.
            Include proper indexing, bounds, and solver syntax for multiple platforms.
            """
        
        elif agent_name == "constraint_modeling":
            return f"""
            Design comprehensive constraint system for this optimization problem:
            {base_info}
            
            Create mathematically sound constraints with solver implementations.
            Ensure completeness, consistency, and computational efficiency.
            """
        
        elif agent_name == "objective_design":
            return f"""
            Design optimal objective functions for this optimization problem:
            {base_info}
            
            Create solver-ready objective formulations with multiple solver implementations.
            Handle multi-objective scenarios and ensure mathematical soundness.
            """
        
        return f"Analyze this optimization problem: {base_info}"
    
    def _create_rl_prompt(self, context: Dict[str, Any]) -> str:
        """Create RL optimization prompt"""
        return f"""
        Apply reinforcement learning optimization to enhance this model:
        
        Intent Analysis: {json.dumps(context['intent_result'])}
        Data Analysis: {json.dumps(context['data_result'])}
        
        Focus on:
        1. Parameter optimization based on historical performance
        2. Adaptive constraint formulations
        3. Dynamic objective weight learning
        4. Performance improvement strategies
        
        Provide RL-based enhancements that improve model performance and adaptability.
        """
    
    def _create_research_prompt(self, context: Dict[str, Any]) -> str:
        """Create research integration prompt"""
        return f"""
        Integrate latest optimization research to enhance this model:
        
        Intent Analysis: {json.dumps(context['intent_result'])}
        Data Analysis: {json.dumps(context['data_result'])}
        
        Focus on:
        1. Latest algorithmic improvements and techniques
        2. Advanced mathematical programming methods
        3. Cutting-edge formulation enhancements
        4. Recent research breakthroughs
        
        Recommend research-based improvements with clear implementation paths.
        """
    
    def _create_ml_prompt(self, context: Dict[str, Any]) -> str:
        """Create ML predictive analytics prompt"""
        return f"""
        Apply machine learning and predictive analytics to enhance this model:
        
        Intent Analysis: {json.dumps(context['intent_result'])}
        Data Analysis: {json.dumps(context['data_result'])}
        
        Focus on:
        1. ML-based demand and parameter forecasting
        2. Uncertainty modeling and robust optimization
        3. Predictive constraints and adaptive parameters
        4. ML-enhanced formulations
        
        Integrate ML predictions and uncertainty modeling for enhanced optimization.
        """
    
    def _assemble_optimization_model(
        self,
        model_id: str,
        intent_result: Dict[str, Any],
        data_result: Dict[str, Any],
        agent_results: Dict[str, Dict[str, Any]]
    ) -> OptimizationModel:
        """Assemble complete optimization model from parallel agent results"""
        
        # Extract core model components
        math_result = agent_results.get("mathematical_formulation", {})
        var_result = agent_results.get("variable_design", {})
        const_result = agent_results.get("constraint_modeling", {})
        obj_result = agent_results.get("objective_design", {})
        
        # Extract enhancement results
        rl_result = agent_results.get("rl_optimization", {})
        research_result = agent_results.get("research_integration", {})
        ml_result = agent_results.get("ml_predictive", {})
        
        # Determine model type
        model_type_str = math_result.get("model_type", "LINEAR_PROGRAMMING")
        try:
            model_type = ModelType(model_type_str.lower())
        except ValueError:
            model_type = ModelType.LINEAR_PROGRAMMING
        
        # Build decision variables
        variables = self._build_decision_variables(var_result)
        
        # Build constraints (with RL/ML enhancements)
        constraints = self._build_constraints(const_result, rl_result, ml_result)
        
        # Build objectives (with RL enhancements)
        objectives = self._build_objectives(obj_result, rl_result)
        
        # Build data schema
        data_schema = self._build_data_schema(intent_result, data_result, variables, constraints)
        
        # Determine solver compatibility
        compatible_solvers = self._determine_compatible_solvers(model_type, math_result)
        recommended_solver = compatible_solvers[0] if compatible_solvers else SolverType.GUROBI
        
        # Calculate model validation score (enhanced by RL/Research/ML)
        base_score = 0.75
        if rl_result.get("status") == "success":
            base_score += 0.10  # RL optimization boost
        if research_result.get("status") == "success":
            base_score += 0.08  # Research integration boost
        if ml_result.get("status") == "success":
            base_score += 0.07  # ML enhancement boost
        
        validation_score = min(0.95, base_score)
        
        return OptimizationModel(
            model_id=model_id,
            model_name=f"enhanced_model_{intent_result.get('primary_intent', 'optimization')}",
            model_type=model_type,
            intent_classification=intent_result.get("primary_intent", "unknown"),
            decision_variables=variables,
            constraints=constraints,
            objective_functions=objectives,
            data_schema=data_schema,
            compatible_solvers=compatible_solvers,
            recommended_solver=recommended_solver,
            model_complexity="medium",
            estimated_solve_time="30-120 seconds",
            model_validation_score=validation_score,
            generation_metadata={
                "generation_timestamp": datetime.now().isoformat(),
                "parallel_generation": True,
                "enhancements": {
                    "rl_applied": rl_result.get("status") == "success",
                    "research_applied": research_result.get("status") == "success", 
                    "ml_applied": ml_result.get("status") == "success"
                }
            }
        )
    
    def _build_decision_variables(self, var_result: Dict[str, Any]) -> List[DecisionVariable]:
        """Build decision variables from agent results"""
        variables = []
        
        if var_result.get("status") == "success":
            var_specs = var_result.get("decision_variables", [])
            
            for var_spec in var_specs:
                bounds = var_spec.get("bounds", {})
                variables.append(DecisionVariable(
                    name=var_spec.get("name", "x"),
                    variable_type=var_spec.get("variable_type", "continuous"),
                    domain=var_spec.get("domain", "real"),
                    bounds=(bounds.get("lower"), bounds.get("upper")),
                    description=var_spec.get("description", "Decision variable"),
                    indices=var_spec.get("indices", []),
                    dimensions=var_spec.get("dimensions", {})
                ))
        else:
            # Fallback default variables
            variables.append(DecisionVariable(
                name="x",
                variable_type="continuous",
                domain="real",
                bounds=(0.0, None),
                description="Production quantities",
                indices=["products", "resources"]
            ))
        
        return variables
    
    def _build_constraints(
        self,
        const_result: Dict[str, Any],
        rl_result: Dict[str, Any],
        ml_result: Dict[str, Any]
    ) -> List[OptimizationConstraint]:
        """Build constraints with RL and ML enhancements"""
        constraints = []
        
        # Base constraints from constraint modeling agent
        if const_result.get("status") == "success":
            const_specs = const_result.get("constraints", [])
            
            for const_spec in const_specs:
                constraints.append(OptimizationConstraint(
                    name=const_spec.get("name", "constraint"),
                    constraint_type=const_spec.get("constraint_type", "inequality"),
                    expression=const_spec.get("expression", "x <= 1"),
                    sense=const_spec.get("sense", "<="),
                    rhs_value=const_spec.get("rhs_value", "1"),
                    description=const_spec.get("description", "Constraint"),
                    priority=const_spec.get("priority", "normal"),
                    constraint_data=const_spec.get("constraint_data", {})
                ))
        
        # Add RL-enhanced adaptive constraints
        if rl_result.get("status") == "success":
            rl_enhancements = rl_result.get("rl_enhancements", {})
            adaptive_constraints = rl_enhancements.get("adaptive_constraints", [])
            
            for adaptive_const in adaptive_constraints:
                constraints.append(OptimizationConstraint(
                    name=f"rl_{adaptive_const.get('constraint_name', 'adaptive')}",
                    constraint_type="inequality",
                    expression=f"rl_adaptive_{adaptive_const.get('constraint_name', 'constraint')}",
                    sense="<=",
                    rhs_value="rl_learned_threshold",
                    description=f"RL-adaptive constraint: {adaptive_const.get('adaptive_mechanism', 'dynamic adjustment')}",
                    priority="important",
                    constraint_data={
                        "rl_mechanism": adaptive_const.get("adaptive_mechanism"),
                        "trigger_conditions": adaptive_const.get("trigger_conditions", []),
                        "learned_parameters": adaptive_const.get("learned_parameters", {})
                    }
                ))
        
        # Add ML-enhanced predictive constraints
        if ml_result.get("status") == "success":
            ml_enhancements = ml_result.get("ml_enhanced_formulations", {})
            predictive_constraints = ml_enhancements.get("predictive_constraints", [])
            
            for pred_const in predictive_constraints:
                constraints.append(OptimizationConstraint(
                    name=f"ml_{pred_const.get('constraint_name', 'predictive')}",
                    constraint_type="inequality",
                    expression=pred_const.get("formulation", "ml_prediction <= threshold"),
                    sense="<=",
                    rhs_value="ml_predicted_threshold",
                    description=f"ML-predictive constraint: {pred_const.get('ml_component', 'predictive modeling')}",
                    priority="important",
                    constraint_data={
                        "ml_component": pred_const.get("ml_component"),
                        "update_frequency": pred_const.get("update_frequency", "static"),
                        "prediction_model": pred_const.get("prediction_model", "ml_model")
                    }
                ))
        
        return constraints
    
    def _build_objectives(
        self,
        obj_result: Dict[str, Any],
        rl_result: Dict[str, Any]
    ) -> List[ObjectiveFunction]:
        """Build objectives with RL enhancements"""
        objectives = []
        
        # Base objectives from objective design agent
        if obj_result.get("status") == "success":
            obj_specs = obj_result.get("objective_functions", [])
            
            for obj_spec in obj_specs:
                # Apply RL weight learning if available
                weight = obj_spec.get("weight", 1.0)
                if rl_result.get("status") == "success":
                    rl_enhancements = rl_result.get("rl_enhancements", {})
                    weight_learning = rl_enhancements.get("objective_weight_learning", {})
                    if weight_learning:
                        # Use RL-learned weights
                        obj_name = obj_spec.get("name", "").lower()
                        if "cost" in obj_name:
                            weight = weight_learning.get("multi_objective_weights", {}).get("cost", weight)
                        elif "time" in obj_name:
                            weight = weight_learning.get("multi_objective_weights", {}).get("time", weight)
                        elif "quality" in obj_name:
                            weight = weight_learning.get("multi_objective_weights", {}).get("quality", weight)
                
                objectives.append(ObjectiveFunction(
                    name=obj_spec.get("name", "objective"),
                    sense=obj_spec.get("sense", "minimize"),
                    expression=obj_spec.get("expression", "minimize_cost"),
                    description=obj_spec.get("description", "Optimization objective"),
                    weight=weight,
                    priority=obj_spec.get("priority", 1)
                ))
        else:
            # Fallback default objective
            objectives.append(ObjectiveFunction(
                name="minimize_cost",
                sense="minimize",
                expression="sum(cost[i] * x[i] for i in products)",
                description="Minimize total cost",
                weight=1.0,
                priority=1
            ))
        
        return objectives
    
    def _build_data_schema(
        self,
        intent_result: Dict[str, Any],
        data_result: Dict[str, Any],
        variables: List[DecisionVariable],
        constraints: List[OptimizationConstraint]
    ) -> ModelDataSchema:
        """Build comprehensive data schema for solver"""
        
        # Extract parameters from constraints and objectives
        parameters = {}
        sets = {}
        scalars = {}
        
        # Common manufacturing parameters
        parameters.update({
            "processing_time": {
                "type": "numerical",
                "description": "Processing time for each product",
                "sample_data": {"P1": 2.0, "P2": 3.0, "P3": 1.5}
            },
            "demand": {
                "type": "numerical", 
                "description": "Demand for each product",
                "sample_data": {"P1": 100, "P2": 150, "P3": 80}
            },
            "capacity": {
                "type": "numerical",
                "description": "Capacity of each production line",
                "sample_data": {"L1": 1000, "L2": 1200, "L3": 900, "L4": 1100}
            }
        })
        
        # Environmental parameters if applicable
        if intent_result.get("primary_intent") == "environmental_optimization":
            parameters.update({
                "carbon_footprint": {
                    "type": "numerical",
                    "description": "Carbon footprint per unit",
                    "sample_data": {"P1": 2.0, "P2": 1.5, "P3": 3.0}
                }
            })
            scalars["carbon_budget"] = 500.0
        
        # Cost parameters if applicable
        if "cost" in intent_result.get("objectives", []):
            parameters.update({
                "unit_cost": {
                    "type": "numerical",
                    "description": "Production cost per unit",
                    "sample_data": {"P1": 10.0, "P2": 12.0, "P3": 8.0}
                }
            })
        
        # Common sets
        sets.update({
            "products": ["P1", "P2", "P3"],
            "production_lines": ["L1", "L2", "L3", "L4"],
            "time_periods": ["T1", "T2", "T3", "T4", "T5", "T6", "T7"]
        })
        
        return ModelDataSchema(
            parameters=parameters,
            sets=sets,
            scalars=scalars
        )
    
    def _determine_compatible_solvers(
        self,
        model_type: ModelType,
        math_result: Dict[str, Any]
    ) -> List[SolverType]:
        """Determine compatible solvers based on model type"""
        
        if model_type == ModelType.LINEAR_PROGRAMMING:
            return [SolverType.GUROBI, SolverType.CPLEX, SolverType.OR_TOOLS, SolverType.PULP, SolverType.CVXPY]
        elif model_type == ModelType.MIXED_INTEGER_PROGRAMMING:
            return [SolverType.GUROBI, SolverType.CPLEX, SolverType.OR_TOOLS, SolverType.PULP]
        elif model_type == ModelType.QUADRATIC_PROGRAMMING:
            return [SolverType.GUROBI, SolverType.CPLEX, SolverType.CVXPY]
        elif model_type == ModelType.NONLINEAR_PROGRAMMING:
            return [SolverType.GUROBI, SolverType.CPLEX]
        else:
            return [SolverType.GUROBI, SolverType.CPLEX, SolverType.OR_TOOLS]
    
    def _create_fallback_model(
        self,
        model_id: str,
        intent_result: Dict[str, Any],
        error_message: str,
        execution_time: float
    ) -> OptimizationModel:
        """Create minimal fallback model on failure"""
        
        return OptimizationModel(
            model_id=model_id,
            model_name=f"fallback_model_{intent_result.get('primary_intent', 'optimization')}",
            model_type=ModelType.LINEAR_PROGRAMMING,
            intent_classification=intent_result.get("primary_intent", "unknown"),
            decision_variables=[
                DecisionVariable(
                    name="x",
                    variable_type="continuous",
                    domain="real",
                    bounds=(0.0, None),
                    description="Decision variables",
                    indices=["products"]
                )
            ],
            constraints=[
                OptimizationConstraint(
                    name="basic_constraint",
                    constraint_type="inequality",
                    expression="sum(x[i] for i in products) <= capacity",
                    sense="<=",
                    rhs_value="capacity",
                    description="Basic capacity constraint"
                )
            ],
            objective_functions=[
                ObjectiveFunction(
                    name="minimize_cost",
                    sense="minimize",
                    expression="sum(cost[i] * x[i] for i in products)",
                    description="Minimize total cost"
                )
            ],
            data_schema=ModelDataSchema(
                parameters={"cost": {"type": "numerical", "description": "Unit costs"}},
                sets={"products": ["P1", "P2", "P3"]},
                scalars={"capacity": 1000.0}
            ),
            compatible_solvers=[SolverType.GUROBI, SolverType.CPLEX, SolverType.OR_TOOLS],
            recommended_solver=SolverType.GUROBI,
            model_complexity="simple",
            estimated_solve_time="< 10 seconds",
            model_validation_score=0.5,
            generation_metadata={
                "fallback_model": True,
                "error_message": error_message,
                "execution_time": execution_time
            }
        )

# ==================== PERFORMANCE BENCHMARKING ====================

class ModelBuilderBenchmark:
    """Benchmark model builder performance and quality"""
    
    @staticmethod
    async def benchmark_model_building_performance():
        """Benchmark parallel vs sequential model building"""
        
        print("âš¡ Model Builder Performance Benchmark")
        print("=" * 60)
        
        # Test data
        intent_result = {
            "primary_intent": "environmental_optimization",
            "confidence": 0.92,
            "objectives": ["minimize_carbon", "maximize_production"],
            "entities": ["carbon_constraints", "production_lines"]
        }
        
        data_result = {
            "query_data_requirements": [
                {"element": "carbon_footprint", "category": "environmental_data", "priority": "critical"},
                {"element": "production_capacity", "category": "production_data", "priority": "critical"}
            ],
            "optimization_readiness": {"data_completeness_score": 0.85}
        }
        
        # Test configurations
        configurations = [
            {"name": "Basic Model", "rl": False, "research": False, "ml": False},
            {"name": "RL Enhanced", "rl": True, "research": False, "ml": False},
            {"name": "Research Enhanced", "rl": False, "research": True, "ml": False},
            {"name": "ML Enhanced", "rl": False, "research": False, "ml": True},
            {"name": "Full Enhancement", "rl": True, "research": True, "ml": True}
        ]
        
        builder = ModelBuilderTool()
        results = []
        
        for config in configurations:
            print(f"\nðŸ§ª Testing: {config['name']}")
            
            times = []
            qualities = []
            
            # Run multiple iterations
            for i in range(3):
                start = datetime.now()
                
                model = await builder.build_optimization_model_parallel(
                    intent_result, data_result, f"bench_{i}",
                    enable_rl=config["rl"],
                    enable_research=config["research"],
                    enable_ml=config["ml"]
                )
                
                execution_time = (datetime.now() - start).total_seconds()
                times.append(execution_time)
                qualities.append(model.model_validation_score)
            
            avg_time = sum(times) / len(times)
            avg_quality = sum(qualities) / len(qualities)
            
            result = {
                "configuration": config["name"],
                "average_time": avg_time,
                "average_quality": avg_quality,
                "enhancements": f"RL:{config['rl']} Research:{config['research']} ML:{config['ml']}",
                "quality_improvement": avg_quality - 0.75,  # Base quality
                "time_cost": avg_time
            }
            
            results.append(result)
            
            print(f"   Time: {avg_time:.1f}s")
            print(f"   Quality: {avg_quality:.3f}")
            print(f"   Enhancement Value: {result['quality_improvement']:.3f}")
        
        # Analysis
        print(f"\nðŸ“Š BENCHMARK RESULTS:")
        print(f"{'Configuration':<18} {'Time':<8} {'Quality':<8} {'Enhancement':<12} {'Efficiency'}")
        print("-" * 70)
        
        for result in results:
            efficiency = result['quality_improvement'] / result['time_cost'] if result['time_cost'] > 0 else 0
            print(f"{result['configuration']:<18} {result['average_time']:<8.1f} {result['average_quality']:<8.3f} {result['quality_improvement']:<12.3f} {efficiency:.3f}")
        
        return results

# ==================== FACTORY FUNCTIONS ====================

def create_model_builder_tool() -> ModelBuilderTool:
    """Create enhanced model builder with RL/Research/ML capabilities"""
    return ModelBuilderTool()

async def build_optimization_model_enhanced(
    intent_result: Dict[str, Any],
    data_result: Dict[str, Any],
    customer_id: str = "default",
    enable_rl: bool = True,
    enable_research: bool = True,
    enable_ml: bool = True
) -> OptimizationModel:
    """Build enhanced optimization model with all capabilities"""
    
    builder = create_model_builder_tool()
    return await builder.build_optimization_model_parallel(
        intent_result, data_result, customer_id, enable_rl, enable_research, enable_ml
    )

# ==================== DEMO AND TESTING ====================

async def demo_enhanced_model_building():
    """Demonstrate enhanced model building with RL/Research/ML"""
    
    print("ðŸš€ Enhanced Model Builder Demo")
    print("=" * 60)
    print("ðŸŽ¯ RL Optimization | ðŸ“š Research Integration | ðŸ¤– ML Predictive Analytics")
    print("=" * 60)
    
    # Test case
    intent_result = {
        "primary_intent": "environmental_optimization",
        "confidence": 0.92,
        "objectives": ["minimize_carbon_footprint", "maximize_production", "minimize_cost"],
        "entities": ["carbon_constraints", "production_lines", "demand_requirements"]
    }
    
    data_result = {
        "query_data_requirements": [
            {"element": "carbon_footprint", "category": "environmental_data", "priority": "critical"},
            {"element": "production_capacity", "category": "production_data", "priority": "critical"},
            {"element": "demand_forecast", "category": "demand_data", "priority": "important"}
        ],
        "optimization_readiness": {"data_completeness_score": 0.85},
        "external_recommendations": [
            {"source": "EPA_carbon_data", "business_value": "high"},
            {"source": "demand_forecasting_api", "business_value": "medium"}
        ]
    }
    
    print("ðŸ“ Problem: Environmental manufacturing optimization")
    print("ðŸŽ¯ Objectives: Minimize carbon, maximize production, minimize cost")
    print("ðŸ“Š Data readiness: 85%")
    
    # Build enhanced model
    print(f"\nðŸ”§ Building enhanced optimization model...")
    start_time = datetime.now()
    
    model = await build_optimization_model_enhanced(
        intent_result, data_result, "demo_customer",
        enable_rl=True, enable_research=True, enable_ml=True
    )
    
    execution_time = (datetime.now() - start_time).total_seconds()
    
    # Display results
    print(f"\nâœ… Enhanced model built in {execution_time:.1f}s")
    print("=" * 60)
    print("ðŸ“Š MODEL SPECIFICATIONS")
    print("=" * 60)
    
    print(f"ðŸ†” Model ID: {model.model_id}")
    print(f"ðŸ“› Model Type: {model.model_type.value}")
    print(f"ðŸŽ¯ Intent: {model.intent_classification}")
    print(f"âœ… Validation Score: {model.model_validation_score:.3f}")
    print(f"ðŸ”§ Recommended Solver: {model.recommended_solver.value}")
    
    print(f"\nðŸ“Š Model Structure:")
    print(f"   Variables: {len(model.decision_variables)}")
    print(f"   Constraints: {len(model.constraints)}")
    print(f"   Objectives: {len(model.objective_functions)}")
    print(f"   Compatible Solvers: {len(model.compatible_solvers)}")
    
    print(f"\nðŸš€ Enhancements Applied:")
    enhancements = model.generation_metadata.get("enhancements_applied", {})
    print(f"   RL Optimization: {'âœ…' if enhancements.get('rl_optimization') else 'âŒ'}")
    print(f"   Research Integration: {'âœ…' if enhancements.get('research_integration') else 'âŒ'}")
    print(f"   ML Predictive: {'âœ…' if enhancements.get('ml_predictive') else 'âŒ'}")
    
    print(f"\nâš¡ Performance:")
    print(f"   Parallel Execution: {model.generation_metadata.get('parallel_execution', False)}")
    print(f"   Successful Agents: {model.generation_metadata.get('successful_agents', 0)}/{model.generation_metadata.get('total_agents', 0)}")
    print(f"   Estimated Solve Time: {model.estimated_solve_time}")
    
    # Sample variable
    if model.decision_variables:
        var = model.decision_variables[0]
        print(f"\nðŸ”¢ Sample Variable: {var.name}")
        print(f"   Type: {var.variable_type}")
        print(f"   Bounds: {var.bounds}")
        print(f"   Description: {var.description}")
    
    # Sample constraint
    if model.constraints:
        const = model.constraints[0]
        print(f"\nâš–ï¸ Sample Constraint: {const.name}")
        print(f"   Expression: {const.expression[:60]}...")
        print(f"   Priority: {const.priority}")
    
    # Data schema
    print(f"\nðŸ“‹ Data Requirements:")
    print(f"   Parameters: {len(model.data_schema.parameters)}")
    print(f"   Sets: {len(model.data_schema.sets)}")
    print(f"   Scalars: {len(model.data_schema.scalars)}")
    
    print(f"\nðŸŽ¯ Ready for Solver Tool: âœ…")
    return model

# ==================== VALIDATION AND TESTING ====================

class ModelValidation:
    """Validate generated optimization models"""
    
    @staticmethod
    def validate_model_structure(model: OptimizationModel) -> Dict[str, Any]:
        """Validate model structure and completeness"""
        
        validation_results = {
            "is_valid": True,
            "errors": [],
            "warnings": [],
            "completeness_score": 0.0
        }
        
        # Check required components
        if not model.decision_variables:
            validation_results["errors"].append("No decision variables defined")
            validation_results["is_valid"] = False
        
        if not model.constraints:
            validation_results["warnings"].append("No constraints defined - model may be unbounded")
        
        if not model.objective_functions:
            validation_results["errors"].append("No objective functions defined")
            validation_results["is_valid"] = False
        
        # Check variable consistency
        for var in model.decision_variables:
            if not var.name:
                validation_results["errors"].append(f"Variable missing name: {var}")
                validation_results["is_valid"] = False
            
            if var.bounds and var.bounds[0] is not None and var.bounds[1] is not None:
                if var.bounds[0] > var.bounds[1]:
                    validation_results["errors"].append(f"Invalid bounds for variable {var.name}: {var.bounds}")
                    validation_results["is_valid"] = False
        
        # Check constraint consistency
        for const in model.constraints:
            if not const.expression:
                validation_results["errors"].append(f"Constraint {const.name} missing expression")
                validation_results["is_valid"] = False
            
            if const.sense not in ["<=", ">=", "=="]:
                validation_results["errors"].append(f"Invalid constraint sense: {const.sense}")
                validation_results["is_valid"] = False
        
        # Check objective consistency
        for obj in model.objective_functions:
            if obj.sense not in ["minimize", "maximize"]:
                validation_results["errors"].append(f"Invalid objective sense: {obj.sense}")
                validation_results["is_valid"] = False
        
        # Calculate completeness score
        score_components = {
            "variables": 0.25 if model.decision_variables else 0,
            "constraints": 0.25 if model.constraints else 0,
            "objectives": 0.25 if model.objective_functions else 0,
            "data_schema": 0.25 if model.data_schema.parameters else 0
        }
        
        validation_results["completeness_score"] = sum(score_components.values())
        
        return validation_results
    
    @staticmethod
    def validate_solver_compatibility(model: OptimizationModel) -> Dict[str, Any]:
        """Validate solver compatibility"""
        
        compatibility_results = {
            "compatible_solvers": [],
            "incompatible_solvers": [],
            "recommendations": []
        }
        
        # Check model type compatibility
        if model.model_type == ModelType.LINEAR_PROGRAMMING:
            compatibility_results["compatible_solvers"] = [
                SolverType.GUROBI, SolverType.CPLEX, SolverType.OR_TOOLS, SolverType.PULP, SolverType.CVXPY
            ]
        elif model.model_type == ModelType.MIXED_INTEGER_PROGRAMMING:
            compatibility_results["compatible_solvers"] = [
                SolverType.GUROBI, SolverType.CPLEX, SolverType.OR_TOOLS, SolverType.PULP
            ]
        elif model.model_type == ModelType.QUADRATIC_PROGRAMMING:
            compatibility_results["compatible_solvers"] = [
                SolverType.GUROBI, SolverType.CPLEX, SolverType.CVXPY
            ]
        else:
            compatibility_results["compatible_solvers"] = [SolverType.GUROBI, SolverType.CPLEX]
        
        # Add recommendations
        if model.model_type == ModelType.MIXED_INTEGER_PROGRAMMING:
            compatibility_results["recommendations"].append("Consider Gurobi or CPLEX for best MIP performance")
        
        if len(model.decision_variables) > 10000:
            compatibility_results["recommendations"].append("Use commercial solvers (Gurobi/CPLEX) for large-scale problems")
        
        return compatibility_results

# ==================== INTEGRATION UTILITIES ====================

class ModelIntegrationUtils:
    """Utilities for integrating with external systems"""
    
    @staticmethod
    def export_to_pyomo(model: OptimizationModel) -> str:
        """Export model to Pyomo format"""
        
        pyomo_code = f"""
# Generated Pyomo model: {model.model_name}
# Model ID: {model.model_id}
# Generated: {datetime.now().isoformat()}

import pyomo.environ as pyo

def create_{model.model_name.replace('-', '_')}():
    model = pyo.ConcreteModel()
    
    # Sets
"""
        
        # Add sets
        for set_name, set_values in model.data_schema.sets.items():
            pyomo_code += f"    model.{set_name} = pyo.Set(initialize={set_values})\n"
        
        # Add parameters
        pyomo_code += "\n    # Parameters\n"
        for param_name, param_data in model.data_schema.parameters.items():
            sample_data = param_data.get("sample_data", {})
            pyomo_code += f"    model.{param_name} = pyo.Param(model.products, initialize={sample_data})\n"
        
        # Add scalars
        pyomo_code += "\n    # Scalars\n"
        for scalar_name, scalar_value in model.data_schema.scalars.items():
            pyomo_code += f"    model.{scalar_name} = pyo.Param(initialize={scalar_value})\n"
        
        # Add variables
        pyomo_code += "\n    # Decision Variables\n"
        for var in model.decision_variables:
            bounds_str = ""
            if var.bounds[0] is not None:
                bounds_str += f"bounds=({var.bounds[0]}, "
                bounds_str += f"{var.bounds[1]}" if var.bounds[1] is not None else "None"
                bounds_str += ")"
            
            domain = "pyo.Reals"
            if var.variable_type == "integer":
                domain = "pyo.Integers"
            elif var.variable_type == "binary":
                domain = "pyo.Binary"
            
            if var.indices:
                index_sets = ", ".join([f"model.{idx}" for idx in var.indices])
                pyomo_code += f"    model.{var.name} = pyo.Var({index_sets}, domain={domain}"
                if bounds_str:
                    pyomo_code += f", {bounds_str}"
                pyomo_code += ")\n"
            else:
                pyomo_code += f"    model.{var.name} = pyo.Var(domain={domain}"
                if bounds_str:
                    pyomo_code += f", {bounds_str}"
                pyomo_code += ")\n"
        
        # Add constraints
        pyomo_code += "\n    # Constraints\n"
        for i, const in enumerate(model.constraints):
            pyomo_code += f"    def {const.name}_rule(model):\n"
            pyomo_code += f"        return {const.expression}\n"
            
            sense_map = {"<=": "pyo.Constraint.Skip", ">=": "pyo.Constraint.Skip", "==": "pyo.Constraint.Skip"}
            pyomo_code += f"    model.{const.name} = pyo.Constraint(rule={const.name}_rule)\n\n"
        
        # Add objectives
        pyomo_code += "    # Objectives\n"
        for obj in model.objective_functions:
            sense = "pyo.minimize" if obj.sense == "minimize" else "pyo.maximize"
            pyomo_code += f"    model.{obj.name} = pyo.Objective(expr={obj.expression}, sense={sense})\n"
        
        pyomo_code += "\n    return model\n\n"
        pyomo_code += f"# Usage: model = create_{model.model_name.replace('-', '_')}()\n"
        
        return pyomo_code
    
    @staticmethod
    def export_to_gurobi(model: OptimizationModel) -> str:
        """Export model to Gurobi format"""
        
        gurobi_code = f"""
# Generated Gurobi model: {model.model_name}
# Model ID: {model.model_id}
# Generated: {datetime.now().isoformat()}

import gurobipy as gp
from gurobipy import GRB

def create_{model.model_name.replace('-', '_')}():
    # Create model
    model = gp.Model("{model.model_name}")
    
    # Data
"""
        
        # Add sets as Python lists
        for set_name, set_values in model.data_schema.sets.items():
            gurobi_code += f"    {set_name} = {set_values}\n"
        
        # Add parameters as dictionaries
        gurobi_code += "\n    # Parameters\n"
        for param_name, param_data in model.data_schema.parameters.items():
            sample_data = param_data.get("sample_data", {})
            gurobi_code += f"    {param_name} = {sample_data}\n"
        
        # Add scalars
        gurobi_code += "\n    # Scalars\n"
        for scalar_name, scalar_value in model.data_schema.scalars.items():
            gurobi_code += f"    {scalar_name} = {scalar_value}\n"
        
        # Add variables
        gurobi_code += "\n    # Decision Variables\n"
        for var in model.decision_variables:
            vtype = "GRB.CONTINUOUS"
            if var.variable_type == "integer":
                vtype = "GRB.INTEGER"
            elif var.variable_type == "binary":
                vtype = "GRB.BINARY"
            
            lb = var.bounds[0] if var.bounds[0] is not None else 0.0
            ub = var.bounds[1] if var.bounds[1] is not None else "GRB.INFINITY"
            
            if var.indices:
                index_sets = ", ".join(var.indices)
                gurobi_code += f"    {var.name} = model.addVars({index_sets}, lb={lb}, ub={ub}, vtype={vtype}, name='{var.name}')\n"
            else:
                gurobi_code += f"    {var.name} = model.addVar(lb={lb}, ub={ub}, vtype={vtype}, name='{var.name}')\n"
        
        # Add constraints
        gurobi_code += "\n    # Constraints\n"
        for const in model.constraints:
            gurobi_code += f"    # {const.description}\n"
            gurobi_code += f"    model.addConstr({const.expression}, name='{const.name}')\n\n"
        
        # Add objectives
        gurobi_code += "    # Objectives\n"
        for obj in model.objective_functions:
            sense = "GRB.MINIMIZE" if obj.sense == "minimize" else "GRB.MAXIMIZE"
            gurobi_code += f"    model.setObjective({obj.expression}, {sense})\n"
        
        gurobi_code += "\n    return model\n\n"
        gurobi_code += f"# Usage:\n"
        gurobi_code += f"# model = create_{model.model_name.replace('-', '_')}()\n"
        gurobi_code += f"# model.optimize()\n"
        
        return gurobi_code
    
    @staticmethod
    def export_to_json(model: OptimizationModel) -> str:
        """Export model to JSON format for API integration"""
        
        model_dict = {
            "model_id": model.model_id,
            "model_name": model.model_name,
            "model_type": model.model_type.value,
            "intent_classification": model.intent_classification,
            "decision_variables": [
                {
                    "name": var.name,
                    "variable_type": var.variable_type,
                    "domain": var.domain,
                    "bounds": var.bounds,
                    "description": var.description,
                    "indices": var.indices,
                    "dimensions": var.dimensions
                }
                for var in model.decision_variables
            ],
            "constraints": [
                {
                    "name": const.name,
                    "constraint_type": const.constraint_type,
                    "expression": const.expression,
                    "sense": const.sense,
                    "rhs_value": const.rhs_value,
                    "description": const.description,
                    "priority": const.priority,
                    "constraint_data": const.constraint_data
                }
                for const in model.constraints
            ],
            "objective_functions": [
                {
                    "name": obj.name,
                    "sense": obj.sense,
                    "expression": obj.expression,
                    "description": obj.description,
                    "weight": obj.weight,
                    "priority": obj.priority
                }
                for obj in model.objective_functions
            ],
            "data_schema": {
                "parameters": model.data_schema.parameters,
                "sets": model.data_schema.sets,
                "scalars": model.data_schema.scalars
            },
            "compatible_solvers": [solver.value for solver in model.compatible_solvers],
            "recommended_solver": model.recommended_solver.value,
            "model_complexity": model.model_complexity,
            "estimated_solve_time": model.estimated_solve_time,
            "model_validation_score": model.model_validation_score,
            "generation_metadata": model.generation_metadata
        }
        
        return json.dumps(model_dict, indent=2, default=str)

# ==================== MAIN EXECUTION ====================

if __name__ == "__main__":
    import sys
    
    async def main():
        """Main execution function"""
        
        print("ðŸš€ DcisionAI Model Builder Tool")
        print("=" * 50)
        
        if len(sys.argv) > 1 and sys.argv[1] == "benchmark":
            # Run benchmark
            await ModelBuilderBenchmark.benchmark_model_building_performance()
        else:
            # Run demo
            model = await demo_enhanced_model_building()
            
            # Validate model
            print("\nðŸ” Model Validation")
            print("=" * 30)
            validation = ModelValidation.validate_model_structure(model)
            print(f"Valid: {validation['is_valid']}")
            print(f"Completeness: {validation['completeness_score']:.1%}")
            print(f"Errors: {len(validation['errors'])}")
            print(f"Warnings: {len(validation['warnings'])}")
            
            # Export examples
            print("\nðŸ“¤ Export Examples")
            print("=" * 30)
            
            # JSON export
            json_export = ModelIntegrationUtils.export_to_json(model)
            print(f"JSON Export: {len(json_export)} characters")
            
            # Pyomo export
            pyomo_export = ModelIntegrationUtils.export_to_pyomo(model)
            print(f"Pyomo Export: {len(pyomo_export)} characters")
            
            # Gurobi export
            gurobi_export = ModelIntegrationUtils.export_to_gurobi(model)
            print(f"Gurobi Export: {len(gurobi_export)} characters")
            
            print(f"\nâœ… Model building demonstration complete!")
            print(f"ðŸŽ¯ Model ready for solver integration")
    
    # Run async main
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nðŸ‘‹ Model builder demo interrupted")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)